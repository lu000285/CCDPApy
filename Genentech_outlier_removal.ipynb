{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date (MM/DD/YY H:MM:SS AM/PM)', 'Cell Line', 'ID', 'Name',\n",
       "       'Initial Volume (mL)', 'Sample Volume (mL)',\n",
       "       'Volume Before Sampling (mL)', 'Volume After Sampling (mL)',\n",
       "       'Feed Media Added (mL)', 'Feed Status', '# Feed', 'Base Added (mL)',\n",
       "       'Osmolarity', 'Viable Cell Concentration (10^6 cells/mL)',\n",
       "       'Dead Cell Concentration (10^6 cells/mL)',\n",
       "       'Total Cell Concentration (10^6 cells/mL)', 'IgG (mg/L)', 'NH4+', 'Na+',\n",
       "       'Titer', 'IntvPCV', 'PCV', 'pCO2', 'pHoff', 'pO2', 'air sparge',\n",
       "       'air sparge sp', 'air sparge total', 'backpressure', 'co2 sparge',\n",
       "       'co2 sparge total', 'do2 controller output', 'do2 primary',\n",
       "       'do2 secondary', 'flowrate overlay', 'oxygen sparge',\n",
       "       'oxygen sparge total', 'ph controller output', 'ph primary',\n",
       "       'pressure exhaust valve', 'sparge total', 'temperature',\n",
       "       'temperature jacket', 'weight load cell', 'Titer_range', 'Titer_group',\n",
       "       'Titer_category', 'Feed', 'Glucose (mM)', 'Lactate (mM)',\n",
       "       'Glucose after feeding (mM)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "df = pd.read_excel(\"input_files/outliers_removal/genentech_12000L_raw.xlsx\")\n",
    "# get column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date (MM/DD/YY H:MM:SS AM/PM)', 'Cell Line', 'ID', 'Name',\n",
       "       'Initial Volume (mL)', 'Sample Volume (mL)',\n",
       "       'Volume Before Sampling (mL)', 'Volume After Sampling (mL)',\n",
       "       'Feed Media Added (mL)', 'Feed Status', '# Feed', 'Base Added (mL)',\n",
       "       'Osmolarity', 'Viable Cell Concentration (10^6 cells/mL)',\n",
       "       'Dead Cell Concentration (10^6 cells/mL)',\n",
       "       'Total Cell Concentration (10^6 cells/mL)', 'IgG (mg/L)', 'NH4+', 'Na+',\n",
       "       'Titer', 'IntvPCV', 'PCV', 'pCO2', 'pHoff', 'pO2', 'air sparge',\n",
       "       'air sparge sp', 'air sparge total', 'backpressure', 'co2 sparge',\n",
       "       'co2 sparge total', 'do2 controller output', 'do2 primary',\n",
       "       'do2 secondary', 'flowrate overlay', 'oxygen sparge',\n",
       "       'oxygen sparge total', 'ph controller output', 'ph primary',\n",
       "       'pressure exhaust valve', 'sparge total', 'temperature',\n",
       "       'temperature jacket', 'weight load cell', 'Titer_range', 'Titer_group',\n",
       "       'Titer_category', 'Feed', 'Glucose (mM)', 'Lactate (mM)',\n",
       "       'Glucose after feeding (mM)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of unique datetimes\n",
    "datetime_lst = df['Date (MM/DD/YY H:MM:SS AM/PM)'].unique().tolist()\n",
    "\n",
    "# get the list of run IDs\n",
    "runID_lst = df['ID'].unique().tolist()\n",
    "# runID_drop_lst = runID_lst[[149,218]]\n",
    "\n",
    "# run 149, 218 have very high initial lactate concentration\n",
    "\n",
    "# add new colum for feeding indicator\n",
    "df['feed bool'] = (df['Glucose (mM)'] != df['Glucose after feeding (mM)']).tolist()\n",
    "\n",
    "feed_idx_lst = df[(df['Glucose (mM)'] != df['Glucose after feeding (mM)'])].index.tolist()\n",
    "\n",
    "\n",
    "# chose the columns to remove outliers\n",
    "cols_lst = [\n",
    "        # 'Date (MM/DD/YY H:MM:SS AM/PM)', 'Cell Line', 'ID', 'Name',\n",
    "    #    'Initial Volume (mL)', 'Sample Volume (mL)',\n",
    "    #    'Volume Before Sampling (mL)', 'Volume After Sampling (mL)',\n",
    "    #    'Feed Media Added (mL)', 'Feed Status', '# Feed', 'Base Added (mL)',\n",
    "       'Osmolarity', 'Viable Cell Concentration (10^6 cells/mL)',\n",
    "       'Dead Cell Concentration (10^6 cells/mL)',\n",
    "       'Total Cell Concentration (10^6 cells/mL)'#, 'IgG (mg/L)', \n",
    "       'NH4+', 'Na+',\n",
    "    #    'Titer', 'IntvPCV', 'PCV', 'pCO2', 'pHoff', 'pO2', 'air sparge',\n",
    "    #    'air sparge sp', 'air sparge total', 'backpressure', 'co2 sparge',\n",
    "    #    'co2 sparge total', 'do2 controller output', 'do2 primary',\n",
    "    #    'do2 secondary', 'flowrate overlay', 'oxygen sparge',\n",
    "    #    'oxygen sparge total', 'ph controller output', 'ph primary',\n",
    "    #    'pressure exhaust valve', 'sparge total', 'temperature',\n",
    "    #    'temperature jacket', 'weight load cell', 'Titer_range', 'Titer_group',\n",
    "    #    'Titer_category', 'Feed',\n",
    "        'Glucose (mM)', 'Lactate (mM)', 'Glucose after feeding (mM)', 'feed bool'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimating_missing_measuremnts(df, runID_lst):\n",
    "    \"\"\"\n",
    "    function to intrapolate/extrapolate missing measurements in dataframe\n",
    "    df: input data frame\n",
    "    runID_lst: unique experimental ID list\n",
    "\n",
    "    Return: df, processed dataframe\n",
    "    \"\"\"\n",
    "    for i, runID in enumerate(runID_lst):\n",
    "        idx_lst = df[df['ID']== runID].index.tolist()\n",
    "        # linear intrapolation/extrapolation\n",
    "        df.loc[idx_lst] = df.interpolate(fill_value=\"extrapolate\",limit_direction=\"both\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_calculation(s_cum, s_conc, s_vol_before_sampling, s_vol_after_sampling, s_conc_after_feeding = None, s_fvol = None, s_fconc = None, prod = False):\n",
    "    \"\"\"\n",
    "    function to calculate the cumulative consumption/production of species\n",
    "\n",
    "    Args:\n",
    "    s_cum: initialized full time series of cumulative consumption/poduction\n",
    "    s_conc: selected time series of species concentration\n",
    "    s_vol_before_sampling: time series of reactor volume (before sampling)\n",
    "    s_vol_after_sampling: time series of reactor volume (after sampling)\n",
    "    s_conc_after_feeding: time series of species concentration after feeding. Default = None\n",
    "    s_fvol = time series of species feeding volume\n",
    "    s_fconc = time series of species feeding concentration\n",
    "    prod = indicator for cumulative production (True) or cumulative consumption (False, default)\n",
    "\n",
    "    Return:\n",
    "    s_cum: time series of cumulative consumption/poduction\n",
    "    \"\"\" \n",
    "    # create copy of s_cum series\n",
    "    s_cum = s_cum.copy()\n",
    "    # create the index list\n",
    "    idx_lst = s_conc.index.tolist()\n",
    "\n",
    "\n",
    "    # check if there is measruement of concentration after feeding\n",
    "    if s_conc_after_feeding is None:\n",
    "    \n",
    "        # check if there is feeding information or not\n",
    "        if s_fvol is None or s_fconc is None:\n",
    "            s_fvol = np.zeros(len(s_cum))\n",
    "            s_fconc = np.zeros(len(s_cum))\n",
    "\n",
    "            # placeholder: need to raise error if both feeding information and concentration after feeding are missing\n",
    "\n",
    "        # calculate the cumulative consumption (mmol)\n",
    "        for i, idx in enumerate(idx_lst):\n",
    "            if i == 0:\n",
    "                s_cum[idx] = 0\n",
    "            else:\n",
    "                s_cum[idx] = s_cum[idx-1] + (s_conc[idx-1]*s_vol_after_sampling[idx-1] + s_fconc[idx-1]*s_fvol[idx-1] - s_conc[idx]*s_vol_before_sampling[idx])/1000\n",
    "        # flip sign if cumulative production\n",
    "        if prod:\n",
    "            s_cum.loc[idx_lst] = -s_cum[idx_lst]\n",
    "\n",
    "    else: # if there is measruement of concentration after feeding\n",
    "\n",
    "        # calculate the cumulative consumption (mmol)\n",
    "        for i, idx in enumerate(idx_lst):\n",
    "            if i == 0:\n",
    "                s_cum[idx] = 0\n",
    "            else:\n",
    "                s_cum[idx] = s_cum[idx-1] + ((s_conc_after_feeding[idx-1] - s_conc[idx])*s_vol_before_sampling[idx])/1000\n",
    "        # flip sign if cumulative production\n",
    "        if prod:\n",
    "            s_cum.loc[idx_lst] = -s_cum[idx_lst]\n",
    "        \n",
    "    return s_cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cumulative lactate consumption\n",
    "df['Cumulative Lactate (mmol)'] = df['Lactate (mM)'].copy()\n",
    "for i in range(len(runID_lst)):\n",
    "    df['Cumulative Lactate (mmol)'] = cumulative_calculation(\n",
    "        df['Cumulative Lactate (mmol)'], df[df['ID']==runID_lst[i]]['Lactate (mM)'],\n",
    "        df[df['ID']==runID_lst[i]]['Volume Before Sampling (mL)'], df[df['ID']==runID_lst[i]]['Volume After Sampling (mL)'],\n",
    "        prod = True)\n",
    "\n",
    "# calculate cumulative lactate consumption\n",
    "df['Cumulative Glucose (mmol)'] = df['Glucose (mM)'].copy()\n",
    "for i in range(len(runID_lst)):\n",
    "    df['Cumulative Glucose (mmol)'] = cumulative_calculation(\n",
    "        df['Cumulative Glucose (mmol)'], df[df['ID']==runID_lst[i]]['Glucose (mM)'],\n",
    "        df[df['ID']==runID_lst[i]]['Volume Before Sampling (mL)'], df[df['ID']==runID_lst[i]]['Volume After Sampling (mL)'],\n",
    "        s_conc_after_feeding = df[df['ID']==runID_lst[i]]['Glucose after feeding (mM)'], prod = False)\n",
    "    \n",
    "# calculate biomass production\n",
    "df['Cumulative viable biomass (cells)'] = df['Viable Cell Concentration (10^6 cells/mL)'].copy()\n",
    "for i in range(len(runID_lst)):\n",
    "    df['Cumulative viable biomass (cells)'] = cumulative_calculation(\n",
    "        df['Cumulative viable biomass (cells)'], df[df['ID']==runID_lst[i]]['Viable Cell Concentration (10^6 cells/mL)'],\n",
    "        df[df['ID']==runID_lst[i]]['Volume Before Sampling (mL)'], df[df['ID']==runID_lst[i]]['Volume After Sampling (mL)']\n",
    "        , prod = True)\n",
    "    \n",
    "df['Cumulative dead biomass (cells)'] = df['Dead Cell Concentration (10^6 cells/mL)'].copy()\n",
    "for i in range(len(runID_lst)):\n",
    "    df['Cumulative dead biomass (cells)'] = cumulative_calculation(\n",
    "        df['Cumulative dead biomass (cells)'], df[df['ID']==runID_lst[i]]['Dead Cell Concentration (10^6 cells/mL)'],\n",
    "        df[df['ID']==runID_lst[i]]['Volume Before Sampling (mL)'], df[df['ID']==runID_lst[i]]['Volume After Sampling (mL)']\n",
    "        , prod = True)\n",
    "    \n",
    "df['Cumulative total biomass (cells)'] = df['Total Cell Concentration (10^6 cells/mL)'].copy()\n",
    "for i in range(len(runID_lst)):\n",
    "    df['Cumulative total biomass (cells)'] = cumulative_calculation(\n",
    "        df['Cumulative total biomass (cells)'], df[df['ID']==runID_lst[i]]['Total Cell Concentration (10^6 cells/mL)'],\n",
    "        df[df['ID']==runID_lst[i]]['Volume Before Sampling (mL)'], df[df['ID']==runID_lst[i]]['Volume After Sampling (mL)']\n",
    "        , prod = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           -0.000000\n",
       "1        39402.468250\n",
       "2        87243.157993\n",
       "3       125494.630417\n",
       "4       155511.813677\n",
       "            ...      \n",
       "6313    133406.239876\n",
       "6314    104603.847202\n",
       "6315     72273.596936\n",
       "6316     60062.240808\n",
       "6317     50959.532771\n",
       "Name: Cumulative Lactate (mmol), Length: 6318, dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['ID']==runID_lst[0]]['Cumulative Lactate (mmol)']\n",
    "df['Cumulative Lactate (mmol)']\n",
    "# df[df['ID']==runID_lst[0]]['Glucose after feeding (mM)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will see if we need this\n",
    "def outlier_removal_other_parameters(measurement_name, runID, s, window = None, threshold = 2):\n",
    "    \"\"\"\n",
    "    function to remove outliers based rolling z-score of time series of a measuresment\n",
    "    Arg:\n",
    "    measurement_name: measurement name\n",
    "    runID: ID of the experimental run\n",
    "    s: time series of data\n",
    "\n",
    "    Return:\n",
    "    s: Processed time series\n",
    "    \"\"\"\n",
    "\n",
    "    if window is None:\n",
    "        window = math.ceil(len(s)/3)\n",
    "\n",
    "    # get a copy of s_con\n",
    "    s = s.copy()\n",
    "    s_raw = s.copy()\n",
    "\n",
    "    # roll = delta_s_cum.rolling(window=window, min_periods=1, closed = 'both', center=True)\n",
    "    roll = s.rolling(window=window, min_periods=1, closed = 'neither', center=True, win_type='gaussian').mean(std=s.mean()*0.1) #both\n",
    "    avg = roll.mean()\n",
    "    std = roll.std() #ddof=0\n",
    "    z = s.sub(avg).div(std)   \n",
    "    m = z.between(-threshold, threshold)\n",
    "    # replace outlier points with rolling average\n",
    "    s = s.where(m, avg)\n",
    "\n",
    "\n",
    "    # create folder to store the smoothed profiles\n",
    "    try:\n",
    "        os.mkdir(\"input_files/outliers_removal\")\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        path = f\"input_files/outliers_removal/{measurement_name}\"\n",
    "        \n",
    "        os.mkdir(path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # before and after plot\n",
    "    s_raw.plot(label='original')\n",
    "    s.plot(label='smoothed')\n",
    "    s[~m].plot(label='corrected values', marker='o', ls='')\n",
    "    s_raw[~m].plot(label='outlier', marker='o', ls='')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{path}/run_{runID}.png\")\n",
    "    plt.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_removal_species(species_name, runID, s_cum, s_conc, s_vol_before_sampling, s_vol_after_sampling, s_conc_after_feeding = None, feed_idx_lst = [], s_fvol = None, s_fconc = None, window = None, threshold = 2, always_consumption = False):\n",
    "    \"\"\"\n",
    "    function to remove outliers based on rolling z-score of time series of delta cumulative consumption/production at specified window size\n",
    "    Arg:\n",
    "    species_name: species name\n",
    "    runID: ID of the experimental run\n",
    "    s_cum: time series of cumulative consumption/production of species\n",
    "    s_conc: time series of concentration of species\n",
    "    s_vol_before_sampling: time series of reactor volumne before sampling\n",
    "    s_vol_after_sampling: time series of reactor volumne after sampling\n",
    "    s_conc_after_feeding: time series of concentration after feeding of species\n",
    "    feed_idx_lst: list of indices that have feedings\n",
    "    s_fvol: time series of feed volumn\n",
    "    s_fconc: time series of feed concentration\n",
    "    window: moving window size (default = (len(s_cum)-1)/3)\n",
    "    threshhold: z-score threshold (default = 3)\n",
    "    always_consumption: True if the species is always consumed/produced\n",
    "\n",
    "    Return \n",
    "    s_conc: processed time series of concentration\n",
    "    \"\"\"\n",
    "    # get a copy of s_con\n",
    "    s_conc = s_conc.copy()\n",
    "    s_conc_raw = s_conc.copy()\n",
    "    # get a copy of s_cum\n",
    "    s_cum = s_cum.copy()\n",
    "    s_cum_raw = s_cum.copy()\n",
    "    \n",
    "    \n",
    "    # remove gluconeogenesis (gluoce production) outlier\n",
    "    if species_name == \"glucose\":\n",
    "        s_cum, s_conc, outlier_idx_lst = remove_gluconeogenesis(s_cum, s_conc, s_vol_before_sampling, s_vol_after_sampling, s_conc_after_feeding, feed_idx_lst, s_fvol, s_fconc)\n",
    "\n",
    "    # get time series of delta cumulative consumption/production\n",
    "    delta_s_cum = delta_cumulative_values_calculation(s_cum)\n",
    "    \n",
    "    delta_s_cum_raw = delta_s_cum.copy()\n",
    "\n",
    "    # outlier removal and get the smoothed delta_s_cum\n",
    "\n",
    "    delta_s_cum, outlier_idx_lst_1st_order = outlier_detector_1st_order(delta_s_cum, window = window, threshold = threshold, always_consumption = always_consumption)\n",
    "    \n",
    "    idx_lst = s_conc.index.tolist()\n",
    "\n",
    "    # restimate the concentration at the detected outlier indices\n",
    "    for i, idx in enumerate(outlier_idx_lst_1st_order):\n",
    "        # check if there is measruement of concentration after feeding\n",
    "        if s_conc_after_feeding is None:\n",
    "            if idx not in feed_idx_lst:    \n",
    "                if idx == idx_lst[0]:\n",
    "                    s_conc.loc[idx] = ((delta_s_cum[idx])*1000 + s_conc[idx+1]*s_vol_before_sampling[idx+1]-s_fconc[idx]*s_fvol[idx])/s_vol_after_sampling[idx]\n",
    "                elif idx == idx_lst[-1]:\n",
    "                    s_conc.loc[idx] = ((-delta_s_cum[idx-1])*1000 + s_conc[idx-1]*s_vol_after_sampling[idx-1]+s_fconc[idx-1]*s_fvol[idx-1])/s_vol_before_sampling[idx]\n",
    "                else:\n",
    "                    s_conc_tmp1 = ((delta_s_cum[idx])*1000 + s_conc[idx+1]*s_vol_before_sampling[idx+1]-s_fconc[idx]*s_fvol[idx])/s_vol_after_sampling[idx]\n",
    "                    s_conc_tmp2 = ((-delta_s_cum[idx-1])*1000 + s_conc[idx-1]*s_vol_after_sampling[idx-1]+s_fconc[idx-1]*s_fvol[idx-1])/s_vol_before_sampling[idx]\n",
    "                    s_conc.loc[idx] = (s_conc_tmp1+s_conc_tmp2)/2\n",
    "            else:\n",
    "                s_conc.loc[idx] = ((-delta_s_cum[idx-1])*1000 + s_conc[idx-1]*s_vol_after_sampling[idx-1]+s_fconc[idx-1]*s_fvol[idx-1])/s_vol_before_sampling[idx]\n",
    "        else:\n",
    "            if idx not in feed_idx_lst:\n",
    "                if idx == idx_lst[0]:\n",
    "                    s_conc.loc[idx] = ((delta_s_cum[idx])*1000 + s_conc[idx+1]*s_vol_before_sampling[idx+1]-s_conc_after_feeding[idx]*s_vol_before_sampling[idx+1]+s_conc[idx]*s_vol_after_sampling[idx])/s_vol_after_sampling[idx]\n",
    "                elif idx == idx_lst[-1]:\n",
    "                    if idx in feed_idx_lst:\n",
    "                        s_conc.loc[idx] = ((-delta_s_cum[idx-1])*1000 + s_conc_after_feeding[idx-1]*s_vol_before_sampling[idx])/s_vol_before_sampling[idx]\n",
    "                    else:\n",
    "                        s_conc.loc[idx] = ((-delta_s_cum[idx-1])*1000 + s_conc[idx-1]*s_vol_before_sampling[idx])/s_vol_before_sampling[idx]\n",
    "                else:\n",
    "                    s_conc_tmp1 = ((delta_s_cum[idx])*1000 + s_conc[idx+1]*s_vol_before_sampling[idx+1]-s_conc_after_feeding[idx]*s_vol_before_sampling[idx+1]+s_conc[idx]*s_vol_after_sampling[idx])/s_vol_after_sampling[idx]\n",
    "                    if idx-1 in feed_idx_lst:\n",
    "                        s_conc_tmp2 = ((-delta_s_cum[idx-1])*1000 + s_conc_after_feeding[idx-1]*s_vol_before_sampling[idx])/s_vol_before_sampling[idx]\n",
    "                    else:\n",
    "                        s_conc_tmp2 = ((-delta_s_cum[idx-1])*1000 + s_conc[idx-1]*s_vol_before_sampling[idx])/s_vol_before_sampling[idx]\n",
    "                    \n",
    "                    s_conc.loc[idx] = (s_conc_tmp1+s_conc_tmp2)/2\n",
    "            else:\n",
    "                if idx-1 in feed_idx_lst:\n",
    "                    s_conc.loc[idx] = ((-delta_s_cum[idx-1])*1000 + s_conc_after_feeding[idx-1]*s_vol_before_sampling[idx])/s_vol_before_sampling[idx]                \n",
    "                else:\n",
    "                    s_conc.loc[idx] = ((-delta_s_cum[idx-1])*1000 + s_conc[idx-1]*s_vol_before_sampling[idx])/s_vol_before_sampling[idx]\n",
    "\n",
    "\n",
    "    # create folder to store the smoothed profiles\n",
    "    try:\n",
    "        os.mkdir(\"input_files/outliers_removal\")\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        path = f\"input_files/outliers_removal/{species_name}\"\n",
    "        \n",
    "        os.mkdir(path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # before and after plot\n",
    "    s_conc_raw.plot(label='original')\n",
    "    s_conc.plot(label='smoothed')\n",
    "    if species_name == \"glucose\":\n",
    "        s_conc[outlier_idx_lst+outlier_idx_lst_1st_order].plot(label='corrected values', marker='o', ls='')\n",
    "        s_conc_raw[outlier_idx_lst+outlier_idx_lst_1st_order].plot(label='outlier', marker='o', ls='')\n",
    "    else:\n",
    "        s_conc[outlier_idx_lst_1st_order].plot(label='corrected values', marker='o', ls='')\n",
    "        s_conc_raw[outlier_idx_lst_1st_order].plot(label='outlier', marker='o', ls='')\n",
    "        \n",
    "    s_conc[[i for i in s_conc_raw.index.tolist() if i in feed_idx_lst]].plot(label='feed', marker='o', ls='')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{path}/run_{runID}.png\")\n",
    "    plt.clf()\n",
    "    \n",
    "    # s_cum_raw.plot(label='original')\n",
    "    # if species_name == \"glucose\":\n",
    "    #     s_cum_raw[outlier_idx_lst].plot(label='outlier', marker='o', ls='')\n",
    "    \n",
    "    # s_cum.plot(label='smoothed')\n",
    "    # plt.legend()\n",
    "    # plt.savefig(f\"{path}/run_{runID}_cum.png\")\n",
    "    # plt.clf()\n",
    "\n",
    "    # delta_s_cum_raw.plot(label='original')\n",
    "    # delta_s_cum_raw[outlier_idx_lst_1st_order].plot(label='outlier', marker='o', ls='')\n",
    "    \n",
    "    # delta_s_cum.plot(label='smoothed')\n",
    "    # plt.legend()\n",
    "    # plt.savefig(f\"{path}/run_{runID}_delta_cum.png\")\n",
    "    # plt.clf()\n",
    "\n",
    "    return s_conc\n",
    "            \n",
    "\n",
    "def remove_gluconeogenesis(s_cum, s_conc, s_vol_before_sampling, s_vol_after_sampling, s_conc_after_feeding, feed_idx_lst, s_fvol, s_fconc):\n",
    "    \"\"\"\n",
    "    function to detect outliers that show abnormal gluoconeogenesis from the time series of glucose cumulative consumption\n",
    "    Arg:\n",
    "    s_cum: time series of cumulative consumption/production of species\n",
    "    s_conc: time series of concentration of species\n",
    "    s_vol_before_sampling: time series of reactor volumne before sampling\n",
    "    s_vol_after_sampling: time series of reactor volumne after sampling\n",
    "    s_conc_after_feeding: time series of concentration after feeding of species\n",
    "    feed_idx_lst: list of indices that have feedings\n",
    "    s_fvol: time series of feed volumn\n",
    "    s_fconc: time series of feed concentration\n",
    "    \n",
    "    Return:\n",
    "    idx_lst: list of detected outlier indices\n",
    "    \"\"\"\n",
    "    # get a copy\n",
    "    s_cum = s_cum.copy()\n",
    "    \n",
    "    # get index list\n",
    "    idx_lst = s_conc.index.tolist()\n",
    "\n",
    "    # check if always_consumption\n",
    "    outliers_idx_1st_lst = []\n",
    "    outliers_idx_2nd_lst = []\n",
    "    for i, idx in enumerate(s_cum.index.tolist()):\n",
    "        if i != 0:\n",
    "            if s_cum[idx] - s_cum[idx-1] < 0:\n",
    "                outliers_idx_2nd_lst.append(idx)\n",
    "                outliers_idx_1st_lst.append(idx-1)\n",
    "    for i in outliers_idx_1st_lst:\n",
    "        s_cum[i] = np.nan\n",
    "    for i in outliers_idx_2nd_lst:\n",
    "        s_cum[i] = np.nan\n",
    "\n",
    "    # get the outlier indices\n",
    "    outlier_idx_lst = s_cum[s_cum.isna()].index.tolist()\n",
    "\n",
    "    # linearly interpolate/extrapolate the NaN points\n",
    "    s_cum = s_cum.interpolate(fill_value=\"extrapolate\",limit_direction=\"both\")\n",
    "    for idx in outlier_idx_lst:\n",
    "        # check if there is measruement of concentration after feeding\n",
    "        if s_conc_after_feeding is None:\n",
    "            if idx == idx_lst[0]:\n",
    "                s_conc.loc[idx] = ((s_cum[idx+1] - s_cum[idx])*1000 + s_conc[idx+1]*s_vol_before_sampling[idx+1]-s_fconc[idx]*s_fvol[idx])/s_vol_after_sampling[idx]\n",
    "            elif idx == idx_lst[-1]:\n",
    "                s_conc.loc[idx] = ((s_cum[idx-1] - s_cum[idx])*1000 + s_conc[idx-1]*s_vol_after_sampling[idx-1]+s_fconc[idx-1]*s_fvol[idx-1])/s_vol_before_sampling[idx]\n",
    "            else:\n",
    "                s_conc_tmp1 = ((s_cum[idx+1] - s_cum[idx])*1000 + s_conc[idx+1]*s_vol_before_sampling[idx+1]-s_fconc[idx]*s_fvol[idx])/s_vol_after_sampling[idx]\n",
    "                s_conc_tmp2 = ((s_cum[idx-1] - s_cum[idx])*1000 + s_conc[idx-1]*s_vol_after_sampling[idx-1]+s_fconc[idx-1]*s_fvol[idx-1])/s_vol_before_sampling[idx]\n",
    "                s_conc.loc[idx] = (s_conc_tmp1+s_conc_tmp2)/2\n",
    "        else:\n",
    "            if idx == idx_lst[0]:\n",
    "                s_conc.loc[idx] = ((s_cum[idx+1] - s_cum[idx])*1000 + s_conc[idx+1]*s_vol_before_sampling[idx+1]-s_conc_after_feeding[idx]*s_vol_before_sampling[idx+1]+s_conc[idx]*s_vol_after_sampling[idx])/s_vol_after_sampling[idx]\n",
    "            elif idx == idx_lst[-1]:\n",
    "                if idx in feed_idx_lst:\n",
    "                    s_conc.loc[idx] = ((s_cum[idx-1] - s_cum[idx])*1000 + s_conc_after_feeding[idx-1]*s_vol_before_sampling[idx])/s_vol_before_sampling[idx]\n",
    "                else:\n",
    "                    s_conc.loc[idx] = ((s_cum[idx-1] - s_cum[idx])*1000 + s_conc[idx-1]*s_vol_before_sampling[idx])/s_vol_before_sampling[idx]\n",
    "            else:\n",
    "                \n",
    "                s_conc_tmp1 = ((s_cum[idx+1] - s_cum[idx])*1000 + s_conc[idx+1]*s_vol_before_sampling[idx+1]-s_conc_after_feeding[idx]*s_vol_before_sampling[idx+1]+s_conc[idx]*s_vol_after_sampling[idx])/s_vol_after_sampling[idx]\n",
    "                if idx-1 in feed_idx_lst:\n",
    "                    s_conc_tmp2 = ((s_cum[idx-1] - s_cum[idx])*1000 + s_conc_after_feeding[idx-1]*s_vol_before_sampling[idx])/s_vol_before_sampling[idx]\n",
    "                else:\n",
    "                    s_conc_tmp2 = ((s_cum[idx-1] - s_cum[idx])*1000 + s_conc[idx-1]*s_vol_before_sampling[idx])/s_vol_before_sampling[idx]\n",
    "\n",
    "                \n",
    "                s_conc.loc[idx] = (s_conc_tmp1+s_conc_tmp2)/2\n",
    "\n",
    "\n",
    "    return s_cum, s_conc, outlier_idx_lst\n",
    "\n",
    "\n",
    "def delta_cumulative_values_calculation(s_cum):\n",
    "    \"\"\"\n",
    "    function to generate the time series of delta cumulative consumption/production, delta_s_cum[t] = s_cum[t+1] - s_cum[t]\n",
    "    Arg:\n",
    "    s_cum: time series of cumulative consumption/production\n",
    "\n",
    "    Return:\n",
    "    delta_s_cum: time series of delta cumulative consumption/production\n",
    "    \"\"\"\n",
    "    # get the index list\n",
    "    idx_lst = s_cum.index.tolist()[:-1]\n",
    "\n",
    "    # initialize delta_s_cum series\n",
    "    delta_s_cum = s_cum[idx_lst[:-1]].copy()\n",
    "\n",
    "    # delta cumulative consumption/production calculate\n",
    "    for i, idx in enumerate(idx_lst):\n",
    "        delta_s_cum.loc[idx] = s_cum[idx+1] - s_cum[idx]\n",
    "\n",
    "    return delta_s_cum\n",
    "\n",
    "def outlier_detector_1st_order(delta_s_cum, window = None, threshold = 3, always_consumption = False):\n",
    "    \"\"\"\n",
    "    function to detect outliers from the time series of delta cumulative values (1st order)\n",
    "    Arg:\n",
    "    delta_s_cum: time series of delta cumulative consumption/production, delta_s_cum[t] = s_cum[t+1] - s_cum[t]\n",
    "    window: moving window size (default = (len(s_cum)-1)/3) for outlier detection using rolling average z-score\n",
    "    threshhold: z-score threshold (default = 3)\n",
    "    always_consumption: True if the species should always get consumed (like glucose)\n",
    "\n",
    "    Return:\n",
    "    idx_lst: list of detected outlier indices\n",
    "    delta_s_cum: processed time series\n",
    "\n",
    "    closedstr for rolling, default None\n",
    "    If 'right', the first point in the window is excluded from calculations.\n",
    "\n",
    "    If 'left', the last point in the window is excluded from calculations.\n",
    "\n",
    "    If 'both', the no points in the window are excluded from calculations.\n",
    "\n",
    "    If 'neither', the first and last points in the window are excluded from calculations.\n",
    "\n",
    "    Default None ('right').\n",
    "    \"\"\"\n",
    "    delta_s_cum = delta_s_cum.copy()\n",
    "    if window is None:\n",
    "        window = math.ceil(len(delta_s_cum)/3)\n",
    "\n",
    "    if always_consumption:\n",
    "        delta_s_cum = delta_s_cum.where(delta_s_cum > 0, np.nan) \n",
    "    \n",
    "    # roll = delta_s_cum.rolling(window=window, min_periods=1, closed = 'both', center=True)\n",
    "    roll = delta_s_cum.rolling(window=window, min_periods=1, closed = 'both', center=True, win_type='gaussian').mean(std=delta_s_cum.mean()*0.2) #both\n",
    "    # roll = delta_s_cum.rolling(window=window, min_periods=1, closed = 'neither', center=True, win_type='gaussian').mean(std=delta_s_cum.mean()*0.1) #both\n",
    "    avg = roll.mean()\n",
    "    std = roll.std() #ddof=0\n",
    "    z = delta_s_cum.sub(avg).div(std)   \n",
    "    m = z.between(-threshold, threshold)\n",
    "    # replace outlier points with NaN \n",
    "    delta_s_cum = delta_s_cum.where(m, np.nan) \n",
    "    # store the list of detected outlier indices\n",
    "    outlier_idx_lst = delta_s_cum[delta_s_cum.isna()].index.tolist()\n",
    "    # interpolate/extrapolate the NaN points using cubicspline\n",
    "    # delta_s_cum = delta_s_cum.interpolate(method='cubicspline',order=3,fill_value=\"extrapolate\",limit_direction=\"both\")\n",
    "    delta_s_cum = delta_s_cum.interpolate(fill_value=\"extrapolate\",limit_direction=\"both\")\n",
    "\n",
    "    # include the adjacent points to be recalculated (mark as outliers as well)\n",
    "    outlier_idx_lst_tmp = []\n",
    "    for i in outlier_idx_lst:\n",
    "        if i+1 not in outlier_idx_lst:\n",
    "            outlier_idx_lst_tmp.append(i+1)\n",
    "    outlier_idx_lst = outlier_idx_lst + outlier_idx_lst_tmp\n",
    "\n",
    "    return delta_s_cum, outlier_idx_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Examples code for processing the data\n",
    "# When adding ro package, create a wrapper function and take agruements that denote species that need to be smoothed\n",
    "\n",
    "# outlier removal\n",
    "for i in range(len(runID_lst)):\n",
    "    idx_lst = df[df['ID']==runID_lst[i]].index.tolist()\n",
    "    # glucose\n",
    "    df.loc[idx_lst, 'Glucose (mM)'] = outlier_removal_species(\n",
    "        \"glucose\", i,#runID_lst[i],\n",
    "        df[df['ID']==runID_lst[i]]['Cumulative Glucose (mmol)'], df[df['ID']==runID_lst[i]]['Glucose (mM)'],\n",
    "        df[df['ID']==runID_lst[i]]['Volume Before Sampling (mL)'], df[df['ID']==runID_lst[i]]['Volume After Sampling (mL)'],\n",
    "        s_conc_after_feeding = df[df['ID']==runID_lst[i]]['Glucose after feeding (mM)'],\n",
    "        feed_idx_lst=feed_idx_lst, window=6, threshold=3, always_consumption = True)#, window=4, window=6\n",
    "    \n",
    "    # Lactate\n",
    "    df.loc[idx_lst, 'Lactate (mM)'] = outlier_removal_species(\n",
    "    \"lactate\", i,#runID_lst[i],\n",
    "    df[df['ID']==runID_lst[i]]['Cumulative Lactate (mmol)'], df[df['ID']==runID_lst[i]]['Lactate (mM)'],\n",
    "    df[df['ID']==runID_lst[i]]['Volume Before Sampling (mL)'], df[df['ID']==runID_lst[i]]['Volume After Sampling (mL)'],\n",
    "    s_fvol = np.zeros(len(df)),\n",
    "    s_fconc = np.zeros(len(df)),\n",
    "    feed_idx_lst=feed_idx_lst, window=6, threshold=3, always_consumption = False)#, window=4, window=5, window=6\n",
    "    # Xv\n",
    "    df.loc[idx_lst, 'Viable Cell Concentration (10^6 cells/mL)'] = outlier_removal_species(\n",
    "    \"Xv\", i,#runID_lst[i],\n",
    "    df[df['ID']==runID_lst[i]]['Cumulative viable biomass (cells)'], df[df['ID']==runID_lst[i]]['Viable Cell Concentration (10^6 cells/mL)'],\n",
    "    df[df['ID']==runID_lst[i]]['Volume Before Sampling (mL)'], df[df['ID']==runID_lst[i]]['Volume After Sampling (mL)'],\n",
    "    s_fvol = np.zeros(len(df)),\n",
    "    s_fconc = np.zeros(len(df)),\n",
    "    feed_idx_lst=feed_idx_lst, window=6, threshold=3, always_consumption = False)#, window=4, window=6\n",
    "\n",
    "    # Xd\n",
    "    df.loc[idx_lst, 'Dead Cell Concentration (10^6 cells/mL)'] = outlier_removal_species(\n",
    "    \"Xd\", i,#runID_lst[i],\n",
    "    df[df['ID']==runID_lst[i]]['Cumulative dead biomass (cells)'], df[df['ID']==runID_lst[i]]['Dead Cell Concentration (10^6 cells/mL)'],\n",
    "    df[df['ID']==runID_lst[i]]['Volume Before Sampling (mL)'], df[df['ID']==runID_lst[i]]['Volume After Sampling (mL)'],\n",
    "    s_fvol = np.zeros(len(df)),\n",
    "    s_fconc = np.zeros(len(df)),\n",
    "    feed_idx_lst=feed_idx_lst, window=6, threshold=3, always_consumption = False)#, window=4, window=6\n",
    "\n",
    "    # Xt\n",
    "    df.loc[idx_lst, 'Total Cell Concentration (10^6 cells/mL)'] = outlier_removal_species(\n",
    "    \"Xt\", i,#runID_lst[i],\n",
    "    df[df['ID']==runID_lst[i]]['Cumulative total biomass (cells)'], df[df['ID']==runID_lst[i]]['Total Cell Concentration (10^6 cells/mL)'],\n",
    "    df[df['ID']==runID_lst[i]]['Volume Before Sampling (mL)'], df[df['ID']==runID_lst[i]]['Volume After Sampling (mL)'],\n",
    "    s_fvol = np.zeros(len(df)),\n",
    "    s_fconc = np.zeros(len(df)),\n",
    "    feed_idx_lst=feed_idx_lst, window=6, threshold=3, always_consumption = False)#, window=4, window=6\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccdpa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
